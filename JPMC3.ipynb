{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output (e.g., from scikit-learn)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Constants ---\n",
        "FILE_PATH = 'JPMC3.csv'\n",
        "RECOVERY_RATE = 0.10\n",
        "LOSS_GIVEN_DEFAULT = 1.0 - RECOVERY_RATE\n",
        "\n",
        "# Define the columns we will use as features (predictors)\n",
        "# 'customer_id' is excluded as it's just an identifier.\n",
        "FEATURE_COLS = [\n",
        "    'credit_lines_outstanding',\n",
        "    'loan_amt_outstanding',\n",
        "    'total_debt_outstanding',\n",
        "    'income',\n",
        "    'years_employed',\n",
        "    'fico_score'\n",
        "]\n",
        "TARGET_COL = 'default' # This is what we want to predict (0 = no default, 1 = default)\n",
        "\n",
        "\n",
        "def calculate_expected_loss(loan_details, model, scaler, feature_cols, lgd):\n",
        "    \"\"\"\n",
        "    Calculates the Probability of Default (PD) and Expected Loss (EL) for a single borrower.\n",
        "\n",
        "    Args:\n",
        "        loan_details (dict): A dictionary containing the borrower's features.\n",
        "                             (e.g., {'income': 50000, 'fico_score': 650, ...})\n",
        "        model (LogisticRegression): The trained logistic regression model.\n",
        "        scaler (StandardScaler): The fitted scaler used for training.\n",
        "        feature_cols (list): The list of feature names in the correct order.\n",
        "        lgd (float): The Loss Given Default (1 - recovery_rate).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing (probability_of_default, expected_loss)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Create a pandas DataFrame from the dict to ensure column order\n",
        "        # This is a robust way to handle the input\n",
        "        # We MUST use 'pandas' here, not 'pd', because we will assign a\n",
        "        # local variable named 'pd' later, which causes a namespace conflict.\n",
        "        # FIX: Changed local variable from 'pd' to 'prob_default'.\n",
        "        # We can now safely use the global 'pd' alias for pandas.\n",
        "        input_df = pd.DataFrame([loan_details])\n",
        "\n",
        "        # Reorder columns to match the exact order the model was trained on\n",
        "        input_data = input_df[feature_cols]\n",
        "\n",
        "        # 2. Scale the input data using the *same* scaler from training\n",
        "        input_scaled = scaler.transform(input_data)\n",
        "\n",
        "        # 3. Predict probability of default (PD)\n",
        "        # model.predict_proba() returns [[prob_class_0, prob_class_1]]\n",
        "        # We want the probability of class 1 (default)\n",
        "        prob_default = model.predict_proba(input_scaled)[0][1]\n",
        "\n",
        "        # 4. Calculate expected loss\n",
        "        # Expected Loss = Probability of Default * Loss Given Default\n",
        "        expected_loss = prob_default * lgd\n",
        "\n",
        "        return prob_default, expected_loss\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in calculating expected loss: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to load data, train the model, and demonstrate the predictor.\n",
        "    \"\"\"\n",
        "    print(\"--- Loan Default Prediction Model ---\")\n",
        "\n",
        "    # --- 1. Load Data ---\n",
        "    try:\n",
        "        data = pd.read_csv(\"JPMC3.csv\")\n",
        "        print(f\"Successfully loaded data from '{FILE_PATH}'. Found {len(data)} records.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Could not find the file '{FILE_PATH}'.\")\n",
        "        print(\"Please make sure the file is in the same directory as this script.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the data: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 2. Data Preprocessing ---\n",
        "\n",
        "    # Check for missing values\n",
        "    if data.isnull().values.any():\n",
        "        print(\"Warning: Missing values found. Dropping rows with NaNs.\")\n",
        "        data = data.dropna()\n",
        "\n",
        "    # Define features (X) and target (y)\n",
        "    X = data[FEATURE_COLS]\n",
        "    y = data[TARGET_COL]\n",
        "\n",
        "    # Split data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    print(f\"Data split: {len(X_train)} training samples, {len(X_test)} testing samples.\")\n",
        "\n",
        "    # --- 3. Feature Scaling ---\n",
        "    # We scale features so that all have a similar range.\n",
        "    # This is important for logistic regression to perform well.\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Fit the scaler ONLY on the training data\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    # Transform the test data using the *same* fitted scaler\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # --- 4. Model Training (Logistic Regression) ---\n",
        "\n",
        "    # Note on model choice:\n",
        "    # We use Logistic Regression because we need to predict a PROBABILITY (a value\n",
        "    # between 0 and 1). Linear Regression is not suitable as it predicts\n",
        "    # continuous values (e.g., -infinity to +infinity) and cannot be\n",
        "    # interpreted as a probability.\n",
        "\n",
        "    print(\"\\nTraining Logistic Regression model...\")\n",
        "    # class_weight='balanced' helps the model handle cases where one class\n",
        "    # (e.g., non-default) is much more common than the other (e.g., default).\n",
        "    model = LogisticRegression(class_weight='balanced', random_state=42)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    print(\"Model training complete.\")\n",
        "\n",
        "    # --- 5. Model Evaluation ---\n",
        "    print(\"\\n--- Model Performance on Test Data ---\")\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # --- 6. Demonstrate the Expected Loss Function ---\n",
        "    print(\"\\n--- Expected Loss Calculation Demo ---\")\n",
        "\n",
        "    # Example 1: A \"good\" borrower profile (high FICO, high income, low debt)\n",
        "    good_borrower = {\n",
        "        'credit_lines_outstanding': 1,\n",
        "        'loan_amt_outstanding': 2000,\n",
        "        'total_debt_outstanding': 5000,\n",
        "        'income': 80000,\n",
        "        'years_employed': 10,\n",
        "        'fico_score': 750\n",
        "    }\n",
        "\n",
        "    prob_default_good, el_good = calculate_expected_loss(good_borrower, model, scaler, FEATURE_COLS, LOSS_GIVEN_DEFAULT)\n",
        "    if prob_default_good is not None:\n",
        "        print(f\"\\nExample 1 (Good Borrower - FICO: 750):\")\n",
        "        print(f\"  > Predicted Probability of Default (PD): {prob_default_good:.2%}\")\n",
        "        print(f\"  > Expected Loss (at {LOSS_GIVEN_DEFAULT*100}% LGD): {el_good:.2%}\")\n",
        "\n",
        "    # Example 2: A \"risky\" borrower profile (low FICO, low income, high debt)\n",
        "    risky_borrower = {\n",
        "        'credit_lines_outstanding': 5,\n",
        "        'loan_amt_outstanding': 15000,\n",
        "        'total_debt_outstanding': 25000,\n",
        "        'income': 35000,\n",
        "        'years_employed': 2,\n",
        "        'fico_score': 580\n",
        "    }\n",
        "\n",
        "    prob_default_risky, el_risky = calculate_expected_loss(risky_borrower, model, scaler, FEATURE_COLS, LOSS_GIVEN_DEFAULT)\n",
        "    if prob_default_risky is not None:\n",
        "        print(f\"\\nExample 2 (Risky Borrower - FICO: 580):\")\n",
        "        print(f\"  > Predicted Probability of Default (PD): {prob_default_risky:.2%}\")\n",
        "        print(f\"  > Expected Loss (at {LOSS_GIVEN_DEFAULT*100}% LGD): {el_risky:.2%}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loan Default Prediction Model ---\n",
            "Successfully loaded data from 'JPMC3.csv'. Found 10000 records.\n",
            "Data split: 8000 training samples, 2000 testing samples.\n",
            "\n",
            "Training Logistic Regression model...\n",
            "Model training complete.\n",
            "\n",
            "--- Model Performance on Test Data ---\n",
            "Accuracy: 0.9955\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1621    9]\n",
            " [   0  370]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      1630\n",
            "           1       0.98      1.00      0.99       370\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.99      1.00      0.99      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "\n",
            "--- Expected Loss Calculation Demo ---\n",
            "\n",
            "Example 1 (Good Borrower - FICO: 750):\n",
            "  > Predicted Probability of Default (PD): 0.00%\n",
            "  > Expected Loss (at 90.0% LGD): 0.00%\n",
            "\n",
            "Example 2 (Risky Borrower - FICO: 580):\n",
            "  > Predicted Probability of Default (PD): 100.00%\n",
            "  > Expected Loss (at 90.0% LGD): 90.00%\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "id": "z5dxzRJrW9Ej",
        "outputId": "65caf56a-2983-419c-e4ff-4146303db96e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jubQ_i3javyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}